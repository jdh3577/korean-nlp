{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_output.shape= (3, ?, 9)\n",
      "sample_id.shape= (3, ?)\n",
      "final_state= LSTMStateTuple(c=<tf.Tensor 'decoder/while/Exit_3:0' shape=(3, 6) dtype=float32>, h=<tf.Tensor 'decoder/while/Exit_4:0' shape=(3, 6) dtype=float32>)\n",
      "final_sequence_lengths.shape= (3,)\n",
      "Tweets\n",
      "[[ 1.  0.  1.]\n",
      " [ 2.  5.  2.]\n",
      " [ 3.  6.  3.]\n",
      " [ 4.  3.  4.]]\n",
      "Replies\n",
      "[[ 2.  3.  4.  5.  8.]\n",
      " [ 5.  6.  4.  3.  8.]\n",
      " [ 2.  3.  4.  5.  8.]]\n",
      "[[ 7.  7.  7.]\n",
      " [ 2.  5.  2.]\n",
      " [ 3.  6.  3.]\n",
      " [ 4.  4.  4.]\n",
      " [ 5.  3.  5.]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(3, 14), b.shape=(14, 24), m=3, n=24, k=14\n\t [[Node: rnn/while/rnn/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/basic_lstm_cell/concat, rnn/while/rnn/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Reshape_2/_191 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1160_SparseSoftmaxCrossEntropyWithLogits/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/while/rnn/basic_lstm_cell/MatMul', defined at:\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-844a7377fffd>\", line 50, in <module>\n    encoder_cell, encoder_emb_inputs, time_major=True, dtype=tf.float32)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 441, in call\n    value=self._linear([inputs, h]), num_or_size_splits=4, axis=1)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2436, in _mat_mul\n    name=name)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(3, 14), b.shape=(14, 24), m=3, n=24, k=14\n\t [[Node: rnn/while/rnn/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/basic_lstm_cell/concat, rnn/while/rnn/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Reshape_2/_191 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1160_SparseSoftmaxCrossEntropyWithLogits/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(3, 14), b.shape=(14, 24), m=3, n=24, k=14\n\t [[Node: rnn/while/rnn/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/basic_lstm_cell/concat, rnn/while/rnn/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Reshape_2/_191 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1160_SparseSoftmaxCrossEntropyWithLogits/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-844a7377fffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;31m# Inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(3, 14), b.shape=(14, 24), m=3, n=24, k=14\n\t [[Node: rnn/while/rnn/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/basic_lstm_cell/concat, rnn/while/rnn/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Reshape_2/_191 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1160_SparseSoftmaxCrossEntropyWithLogits/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/while/rnn/basic_lstm_cell/MatMul', defined at:\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-844a7377fffd>\", line 50, in <module>\n    encoder_cell, encoder_emb_inputs, time_major=True, dtype=tf.float32)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 441, in call\n    value=self._linear([inputs, h]), num_or_size_splits=4, axis=1)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2436, in _mat_mul\n    name=name)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"c:\\users\\jinhak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(3, 14), b.shape=(14, 24), m=3, n=24, k=14\n\t [[Node: rnn/while/rnn/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/basic_lstm_cell/concat, rnn/while/rnn/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Reshape_2/_191 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1160_SparseSoftmaxCrossEntropyWithLogits/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    batch_size=3,\n",
    "    encoder_length=4,\n",
    "    decoder_length=5,\n",
    "    num_units=6,\n",
    "    src_vocab_size=7,\n",
    "    embedding_size=8,\n",
    "    tgt_vocab_size=9,\n",
    "    learning_rate = 0.01,\n",
    "    max_gradient_norm = 5.0,\n",
    "    beam_width =9,\n",
    "    use_attention = False,\n",
    ")\n",
    "\n",
    "# Symbol for start decode process.\n",
    "tgt_sos_id = 7\n",
    "\n",
    "# Symbol for end of decode process.\n",
    "tgt_eos_id = 8\n",
    "\n",
    "# For debug purpose.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Encoder\n",
    "#   encoder_inputs: [encoder_length, batch_size]\n",
    "#   This is time major where encoder_length comes first instead of batch_size.\n",
    "encoder_inputs = tf.placeholder(tf.int32, shape=(hparams.encoder_length, hparams.batch_size), name=\"encoder_inputs\")\n",
    "\n",
    "# Embedding\n",
    "#   Matrix for embedding: [src_vocab_size, embedding_size]\n",
    "embedding_encoder = tf.get_variable(\n",
    "    \"embedding_encoder\", [hparams.src_vocab_size, hparams.embedding_size])\n",
    "\n",
    "# Look up embedding:\n",
    "#   encoder_inputs: [encoder_length, batch_size]\n",
    "#   encoder_emb_inputs: [encoder_length, batch_size, embedding_size]\n",
    "encoder_emb_inputs = tf.nn.embedding_lookup(embedding_encoder, encoder_inputs)\n",
    "\n",
    "# LSTM cell.\n",
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)\n",
    "\n",
    "# Run Dynamic RNN\n",
    "#   encoder_outputs: [encoder_length, batch_size, num_units]\n",
    "#   encoder_state: [batch_size, num_units], this is final state of the cell for each batch.\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_emb_inputs, time_major=True, dtype=tf.float32)\n",
    "\n",
    "# Decoder input\n",
    "#   decoder_inputs: [decoder_length, batch_size]\n",
    "#   decoder_lengths: [batch_size]\n",
    "#   This is grand truth target inputs for training.\n",
    "decoder_inputs = tf.placeholder(tf.int32, shape=(hparams.decoder_length, hparams.batch_size), name=\"decoder_inputs\")\n",
    "decoder_lengths = tf.placeholder(tf.int32, shape=(hparams.batch_size), name=\"decoer_length\")\n",
    "\n",
    "# EmbeddingDecoder:\n",
    "#    Embedding for decoder.\n",
    "#    This is used to convert encode training target texts to list of ids.\n",
    "embedding_decoder = tf.get_variable(\n",
    "    \"embedding_decoder\", [hparams.tgt_vocab_size, hparams.embedding_size])\n",
    "\n",
    "\n",
    "# Look up embedding:\n",
    "#   decoder_inputs: [decoder_length, batch_size]\n",
    "#   decoder_emb_inp: [decoder_length, batch_size, embedding_size]\n",
    "decoder_emb_inputs = tf.nn.embedding_lookup(embedding_decoder, decoder_inputs)\n",
    "\n",
    "# https://stackoverflow.com/questions/39573188/output-projection-in-seq2seq-model-tensorflow\n",
    "# Internally, a neural network operates on dense vectors of some size,\n",
    "# often 256, 512 or 1024 floats (let's say 512 for here).\n",
    "# But at the end it needs to predict a word from the vocabulary which is often much larger,\n",
    "# e.g., 40000 words. Output projection is the final linear layer that converts (projects) from the internal representation to the larger one.\n",
    "# So, for example, it can consist of a 512 x 40000 parameter matrix and a 40000 parameter for the bias vector.\n",
    "projection_layer = layers_core.Dense(\n",
    "            hparams.tgt_vocab_size, use_bias=False)\n",
    "\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(decoder_emb_inputs, decoder_lengths, time_major=True)\n",
    "\n",
    "# Decoder with helper:\n",
    "#   decoder_emb_inputs: [decoder_length, batch_size, embedding_size]\n",
    "#   decoder_length: [batch_size] vector, which represents each target sequence length.\n",
    "decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)\n",
    "\n",
    "if hparams.use_attention:\n",
    "  # Attention\n",
    "  # attention_states: [batch_size, max_time, num_units]\n",
    "  attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "  # Create an attention mechanism\n",
    "  attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "      hparams.num_units, attention_states,\n",
    "      memory_sequence_length=None)\n",
    "\n",
    "  decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "      decoder_cell, attention_mechanism,\n",
    "      attention_layer_size=hparams.num_units)\n",
    "\n",
    "  initial_state = decoder_cell.zero_state(hparams.batch_size, tf.float32).clone(cell_state=encoder_state)\n",
    "else:\n",
    "  initial_state = encoder_state\n",
    "\n",
    "# Decoder and decode\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "#   final_outputs.rnn_output: [batch_size, decoder_length, tgt_vocab_size], list of RNN state.\n",
    "#   final_outputs.sample_id: [batch_size, decoder_length], list of argmax of rnn_output.\n",
    "#   final_state: [batch_size, num_units], list of final state of RNN on decode process.\n",
    "#   final_sequence_lengths: [batch_size], list of each decoded sequence.\n",
    "\n",
    "final_outputs, _final_state, _final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "print(\"rnn_output.shape=\", final_outputs.rnn_output.shape)\n",
    "print(\"sample_id.shape=\", final_outputs.sample_id.shape)\n",
    "print(\"final_state=\", _final_state)\n",
    "print(\"final_sequence_lengths.shape=\", _final_sequence_lengths.shape)\n",
    "\n",
    "logits = final_outputs.rnn_output\n",
    "\n",
    "# Target labels\n",
    "#   As described in doc for sparse_softmax_cross_entropy_with_logits,\n",
    "#   labels should be [batch_size, decoder_lengths] instead of [batch_size, decoder_lengths, tgt_vocab_size].\n",
    "#   So labels should have indices instead of tgt_vocab_size classes.\n",
    "target_labels = tf.placeholder(tf.int32, shape=(hparams.batch_size, hparams.decoder_length))\n",
    "\n",
    "# Loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_labels, logits=logits)\n",
    "\n",
    "# Train\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# Calculate and clip gradients\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "    gradients, hparams.max_gradient_norm)\n",
    "\n",
    "# Optimization\n",
    "optimizer = tf.train.AdamOptimizer(hparams.learning_rate)\n",
    "train_op = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params), global_step=global_step)\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(hparams.learning_rate)\n",
    "#train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training data.\n",
    "\n",
    "# Tweet\n",
    "tweet1 = np.array([1, 2, 3, 4])\n",
    "tweet2 = np.array([0, 5, 6, 3])\n",
    "\n",
    "# Make batch data.\n",
    "train_encoder_inputs = np.empty((hparams.encoder_length, hparams.batch_size))\n",
    "train_encoder_inputs[:, 0] = tweet1\n",
    "train_encoder_inputs[:, 1] = tweet2\n",
    "train_encoder_inputs[:, 2] = tweet1\n",
    "print(\"Tweets\")\n",
    "print(train_encoder_inputs)\n",
    "\n",
    "# Reply\n",
    "training_decoder_input1 = [tgt_sos_id, 2, 3, 4, 5]\n",
    "training_decoder_input2 = [tgt_sos_id, 5, 6, 4, 3]\n",
    "\n",
    "training_target_label1 = [2, 3, 4, 5, tgt_eos_id]\n",
    "training_target_label2 = [5, 6, 4, 3, tgt_eos_id]\n",
    "\n",
    "training_target_labels = np.empty((hparams.batch_size, hparams.decoder_length))\n",
    "training_target_labels[0] = training_target_label1\n",
    "training_target_labels[1] = training_target_label2\n",
    "training_target_labels[2] = training_target_label1\n",
    "print(\"Replies\")\n",
    "print(training_target_labels)\n",
    "\n",
    "training_decoder_inputs = np.empty((hparams.decoder_length, hparams.batch_size))\n",
    "training_decoder_inputs[:, 0] = training_decoder_input1\n",
    "training_decoder_inputs[:, 1] = training_decoder_input2\n",
    "training_decoder_inputs[:, 2] = training_decoder_input1\n",
    "print(training_decoder_inputs)\n",
    "\n",
    "feed_dict = {\n",
    "    encoder_inputs: train_encoder_inputs,\n",
    "    target_labels: training_target_labels,\n",
    "    decoder_inputs: training_decoder_inputs,\n",
    "    decoder_lengths: np.ones((hparams.batch_size), dtype=int) * hparams.decoder_length\n",
    "}\n",
    "\n",
    "# Train\n",
    "for i in range(100):\n",
    "  _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "\n",
    "# Inference\n",
    "inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "    embedding_decoder,\n",
    "    tf.fill([hparams.batch_size], tgt_sos_id), tgt_eos_id)\n",
    "\n",
    "# Inference Decoder\n",
    "inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    decoder_cell, inference_helper, initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "\n",
    "# We should specify maximum_iterations, it can't stop otherwise.\n",
    "source_sequence_length = hparams.encoder_length\n",
    "maximum_iterations = tf.round(tf.reduce_max(source_sequence_length) * 2)\n",
    "\n",
    "# Dynamic decoding\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "    inference_decoder, maximum_iterations=maximum_iterations)\n",
    "translations = outputs.sample_id\n",
    "\n",
    "# Input tweets\n",
    "inference_encoder_inputs = np.empty((hparams.encoder_length, hparams.batch_size))\n",
    "inference_encoder_inputs[:, 0] = tweet1\n",
    "inference_encoder_inputs[:, 1] = tweet2\n",
    "inference_encoder_inputs[:, 2] = tweet1\n",
    "\n",
    "feed_dict = {\n",
    "    encoder_inputs: inference_encoder_inputs,\n",
    "}\n",
    "\n",
    "replies = sess.run([translations], feed_dict=feed_dict)\n",
    "print(replies)\n",
    "\n",
    "# Beam Search\n",
    "# Replicate encoder infos beam_width times\n",
    "decoder_initial_state = tf.contrib.seq2seq.tile_batch(\n",
    "    initial_state, multiplier=hparams.beam_width)\n",
    "\n",
    "# Define a beam-search decoder\n",
    "inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "        cell=decoder_cell,\n",
    "        embedding=embedding_decoder,\n",
    "        start_tokens=tf.fill([hparams.batch_size], tgt_sos_id),\n",
    "        end_token=tgt_eos_id,\n",
    "        initial_state=decoder_initial_state,\n",
    "        beam_width=hparams.beam_width,\n",
    "        output_layer=projection_layer,\n",
    "        length_penalty_weight=0.0)\n",
    "\n",
    "# Dynamic decoding\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "    inference_decoder, maximum_iterations=maximum_iterations)\n",
    "translations = outputs.predicted_ids\n",
    "\n",
    "replies = sess.run([translations], feed_dict=feed_dict)\n",
    "print(replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
