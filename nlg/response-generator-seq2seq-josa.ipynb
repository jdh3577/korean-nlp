{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"영화관스파이더맨상영합?',\", '영화관에서스파이더맨을상영합니까'], [\"'몇장의티켓필요하십니까?',\", '몇장의티켓이필요하십니까'], [\"'영화표0장원합니다',\", '영화표0장을원합니다'], [\"'서울특별시이용가능합니다',\", '서울특별시에서이용가능합니다'], [\"'cgv성신여대입구이용가능합니다',\", 'cgv성신여대입구에서이용가능합니다'], [\"'0일원합니다',\", '0일에원합니다'], [\"'0시상영하는영화표필요합니다',\", '0시에상영하는영화표가필요합니다'], [\"'감사합니다'\", '감사합니다'], [\"'0시이용가능합니다.',\", '0시에이용가능합니다'], [\"'영화표0장원합니다!',\", '영화표0장을원합니다'], [\"'cgv수원이용가능합니다',\", 'cgv수원에서이용가능합니다'], [\"'안양이용가능합니다',\", '안양에서이용가능합니다'], [\"'0시이용가능합니다.',\", '0시에이용가능합니다'], [\"'0일인비저블게스트예매할수있습니까?',\", '0일에인비저블게스트를예매할수있습니까'], [\"'서울특별시영화보기원합니다.',\", '서울특별시에서영화를보기원합니다'], [\"'0시이용가능합니다.',\", '0시에이용가능합니다'], [\"'영화표0장원합니다',\", '영화표0장을원합니다'], [\"'몇시보고싶습니까?',\", '몇시에보고싶습니까'], [\"'0일지정하기원합니다.',\", '0일에지정하기원합니다'], [\"'어느영화관가능합니까?',\", '어느영화관이가능합니까'], [\"'어느영화관은평구인비저블게스트상영합?',\", '어느영화관이은평구인비저블게스트상영합니까'], [\"'0일이용가능합니다.',\", '0일에이용가능합니다'], [\"'0장예매할수있습니까?',\", '0장을예매할수있습니까'], [\"'예매도주실수있으세요?',\", '예매를도와주실수있으세요'], [\"'어떤도시원합니까?',\", '어떤도시를원합니까'], [\"'0시이용가능합니다.',\", '0시에이용가능합니다'], [\"'서울특별시상영하는영화표필요합니다.',\", '서울특별시에서상영하는영화표가필요합니다'], [\"'0일cgv범계0시상영하는인비저블게스트0장예매했습니다.'\", '0일cgv범계에서0시에상영하는인비저블게스트0장을예매했습니다'], ['수원시상영중인날짜몇일입', '수원시에서상영중인날짜는몇일입니까'], ['0일지정하기를원합니다.', '0일에지정하기를원합니다'], ['영화표0장원합니다!', '영화표0장을원합니다'], ['영화표0장예매하고싶습니다.', '영화표0장을예매하고싶습니다'], ['0일이용가능합니다.', '0일에이용가능합니다'], ['0시상영하는영화보기원합니다.', '0시에상영하는영화를보기원합니다'], ['네,주세요', '네주세요'], ['cgv강변여배우오늘예매할수있습니까?', 'cgv강변여배우는오늘도예매할수있습니까'], ['어떤여자배우좋아합니까?', '어떤여자배우를좋아합니까'], ['여배우오늘보기원합니다.', '여배우는오늘도보기원합니다'], ['0시상영하는영화보기원합니다.', '0시에상영하는영화를보기원합니다'], ['롯데시네마건대입구이용가능합니다.', '롯데시네마건대입구에서이용가능합니다'], ['감사합니다.', '감사합니다'], ['인비저블게스트0장예매할수있습니까?', '인비저블게스트0장을예매할수있습니까'], ['살인자기억법예매할수있습니까?', '살인자의기억법을예매할수있습니까'], ['0시이용가능합니다.', '0시에이용가능합니다'], ['0일지정하기원합니다.', '0일에지정하기원합니다'], ['해당티켓구입원하십니까?', '해당티켓구입을원하십니까'], ['어느영화관원하십니까?', '어느영화관을원하십니까'], ['0시이용가능합니다.', '0시에이용가능합니다'], ['0일지정하기원합니다.', '0일에지정하기원합니다'], ['0일이용가능합니다.', '0일에이용가능합니다'], ['영화표0장원합니다!', '영화표0장을원합니다'], ['어느영화관0시아메리칸메이드상영합?', '어느영화관이0시에아메리칸메이드를상영합니까'], ['0일서울특별시롯데시네마건대입구0시상영하는아메리칸메이드0장예매했습니다.', '0일서울특별시의롯데시네마건대입구에서0시에상영하는아메리칸메이드0장을예매했습니다'], ['롯데시네마건대입구이용가능합니다.', '롯데시네마건대입구에서이용가능합니다'], ['서울특별시영화보기원합니다.', '서울특별시에서영화를보기원합니다'], ['요청하신0일0시경기도안양시cgv범계상영하는잃어버린도시0장예매완료하였습니다', '요청하신0일0시에경기도안양시cgv범계에서상영하는잃어버린도시0장을예매완료하였습니다'], ['cgv군자영화보기원합니다', 'cgv군자에서영화를보기원합니다'], ['', ''], ['', '']]\n",
      "Char List : {'였': 114, '롯': 65, '양': 66, '완': 67, '성': 68, '와': 69, '중': 0, '세': 70, '[': 123, '이': 71, '데': 72, ',': 111, '했': 73, '주': 1, '예': 2, '표': 74, '게': 75, '변': 4, '원': 103, '저': 76, '자': 6, '료': 7, '사': 8, '영': 78, '서': 9, '니': 10, '리': 14, 'v': 12, '까': 13, '감': 80, '스': 81, '은': 79, \"'\": 16, '범': 82, '0': 17, ']': 124, '기': 84, '건': 117, '우': 11, '켓': 85, '입': 86, '필': 19, '용': 20, '화': 21, 'P': 125, '으': 87, '십': 106, '몇': 88, '있': 33, '아': 22, '안': 89, '잃': 50, '좋': 24, '보': 92, '평': 25, '수': 97, '가': 26, '네': 15, 'c': 27, '도': 28, '군': 112, '늘': 30, '당': 93, '법': 90, '해': 31, '고': 94, '.': 91, '신': 95, '습': 96, '블': 23, '장': 32, '칸': 18, '날': 34, '특': 98, '능': 35, '관': 36, '할': 99, '계': 100, '울': 109, '일': 101, '배': 102, 'g': 37, '린': 104, '하': 38, '티': 40, '실': 41, '을': 105, '상': 42, '어': 107, '에': 108, '는': 110, '구': 43, '시': 44, '트': 58, '강': 45, '?': 46, '파': 47, '별': 83, '정': 113, '싶': 48, '를': 49, '요': 3, '인': 51, '지': 53, '대': 62, '떤': 115, '메': 54, '살': 116, '여': 77, '!': 55, '맨': 56, '합': 57, '매': 59, '억': 60, '오': 29, '다': 61, '청': 5, '드': 118, '마': 119, '비': 52, '버': 63, '경': 120, '더': 64, '느': 121, '의': 39, '짜': 122}\n",
      "Char Size : 126\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# The paths of RNNCell or rnn functions are too long.\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops import *\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import *\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import *\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "mecab = Twitter()\n",
    "\n",
    "\n",
    "def get_normalized_data(sentence):\n",
    "    original_sentence = mecab.pos(sentence)\n",
    "    inputData = []\n",
    "    for w, t in original_sentence:\n",
    "        if t in ['Number']:\n",
    "            w = '0'\n",
    "        if t not in ['Punctuation']:\n",
    "            inputData.append(w)\n",
    "    return ''.join(inputData)\n",
    "\n",
    "\n",
    "def get_training_data(sentence):\n",
    "    original_sentence = mecab.pos(sentence)\n",
    "    inputData = []\n",
    "    for w, t in original_sentence:\n",
    "        if t in ['Number']:\n",
    "            w = '0'\n",
    "        if t not in ['Josa']:\n",
    "            inputData.append(w)\n",
    "    return ''.join(inputData)\n",
    "\n",
    "# input_data = []\n",
    "# for i in text_data:\n",
    "#     input_data.append(get_training_data(i))\n",
    "\n",
    "text_read_input =[]\n",
    "f = open(\"./text2.txt\", 'r', encoding='utf-8')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if line == '\\n':\n",
    "        del line\n",
    "    else:\n",
    "        text_read_input.append(line)\n",
    "        if not line: break\n",
    "f.close()\n",
    "\n",
    "text_read_input_data = []\n",
    "for i in text_read_input:\n",
    "    text_read_input_data.append(get_normalized_data(i))\n",
    "\n",
    "input_data = []\n",
    "for i in text_read_input:\n",
    "    input_data.append(get_training_data(i))\n",
    "\n",
    "# train_data = [[x] + [y] for x,y in zip(input_data, text_data)]\n",
    "train_data = [[x] + [y] for x,y in zip(input_data, text_read_input_data)]\n",
    "\n",
    "\n",
    "char_array = []\n",
    "all_char = ''\n",
    "for text in train_data:\n",
    "    all_char = all_char + ''.join(text)\n",
    "char_array = list(set(all_char)) + ['[',']','P']\n",
    "print(train_data)\n",
    "\n",
    "max_input_text = max(len(s[0]) for s in train_data)\n",
    "max_output_text = max(len(s[1]) for s in train_data)\n",
    "# enumerate 방법 사용 index : value 정렬\n",
    "num_dic = {n: i for i, n in enumerate(char_array)}\n",
    "\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "print (\"Char List : \" + str(num_dic))\n",
    "print (\"Char Size : \" + str(dic_len))\n",
    "\n",
    "index_in_epoch = 0\n",
    "\n",
    "def make_train_data(train_data, batch_size=16, isTrain=True):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    if isTrain:\n",
    "        global index_in_epoch\n",
    "        start = index_in_epoch\n",
    "        if index_in_epoch + batch_size < len(train_data) -1:\n",
    "            index_in_epoch = index_in_epoch + batch_size\n",
    "        else:\n",
    "            index_in_epoch = 0\n",
    "        batch_set = train_data[start:start+batch_size]\n",
    "    else:\n",
    "        batch_set = train_data\n",
    "\n",
    "    for seq in batch_set:\n",
    "        # 인코더 셀의 입력값. 입력단어의 글자들을 한글자씩 떼어 배열로 만든다.\n",
    "        input = [num_dic[n] for n in seq[0]+'P' * (max_input_text - len(seq[0]))]\n",
    "        # 디코더 셀의 입력값. 시작을 나타내는 [ 심볼을 맨 앞에 붙여준다.\n",
    "        output = [num_dic[n] for n in ('[' + seq[1] + 'P' * (max_output_text - len(seq[1])))]\n",
    "        # 학습을 위해 비교할 디코더 셀의 출력값. 끝나는 것을 알려주기 위해 마지막에 ] 를 붙인다.\n",
    "        target = [num_dic[n] for n in (seq[1] + 'P' * (max_output_text - len(seq[1])) + ']' )]\n",
    "        input_batch.append(input)\n",
    "        output_batch.append(output)\n",
    "        target_batch.append(target)\n",
    "    return input_batch, output_batch, target_batch\n",
    "\n",
    "\n",
    "file_path = './model'\n",
    "def model_file(file_path, flag):\n",
    "    if(flag):\n",
    "        import os\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "        if(not os.path.exists(file_path)):\n",
    "            os.makedirs(file_path)\n",
    "        saver.save(sess, ''.join(file_path + \"/.model\"))\n",
    "        print(\"Model Saved\")\n",
    "    else:\n",
    "        import shutil\n",
    "        try:\n",
    "            shutil.rmtree(file_path)\n",
    "            print(\"Model Deleted\")\n",
    "        except OSError as e:\n",
    "            if e.errno == 2:\n",
    "                # 파일이나 디렉토리가 없음!\n",
    "                print ('No such file or directory to remove')\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/30000 Iteration: 0 Train loss: 4.927\n",
      "Epoch: 500/30000 Iteration: 500 Train loss: 1.391\n",
      "Epoch: 1000/30000 Iteration: 1000 Train loss: 0.526\n",
      "Epoch: 1500/30000 Iteration: 1500 Train loss: 0.550\n",
      "Epoch: 2000/30000 Iteration: 2000 Train loss: 0.130\n",
      "Epoch: 2500/30000 Iteration: 2500 Train loss: 0.124\n",
      "Epoch: 3000/30000 Iteration: 3000 Train loss: 0.122\n",
      "Epoch: 3500/30000 Iteration: 3500 Train loss: 0.120\n",
      "Epoch: 4000/30000 Iteration: 4000 Train loss: 0.118\n",
      "Epoch: 4500/30000 Iteration: 4500 Train loss: 0.120\n",
      "Epoch: 5000/30000 Iteration: 5000 Train loss: 0.118\n",
      "Epoch: 5500/30000 Iteration: 5500 Train loss: 0.367\n",
      "Epoch: 6000/30000 Iteration: 6000 Train loss: 0.117\n",
      "Epoch: 6500/30000 Iteration: 6500 Train loss: 0.121\n",
      "Epoch: 7000/30000 Iteration: 7000 Train loss: 0.118\n",
      "Epoch: 7500/30000 Iteration: 7500 Train loss: 0.117\n",
      "Epoch: 8000/30000 Iteration: 8000 Train loss: 0.118\n",
      "Epoch: 8500/30000 Iteration: 8500 Train loss: 0.117\n",
      "Epoch: 9000/30000 Iteration: 9000 Train loss: 0.117\n",
      "Epoch: 9500/30000 Iteration: 9500 Train loss: 0.117\n",
      "Epoch: 10000/30000 Iteration: 10000 Train loss: 0.118\n",
      "Epoch: 10500/30000 Iteration: 10500 Train loss: 0.117\n",
      "Epoch: 11000/30000 Iteration: 11000 Train loss: 0.118\n",
      "Epoch: 11500/30000 Iteration: 11500 Train loss: 0.116\n",
      "Epoch: 12000/30000 Iteration: 12000 Train loss: 0.118\n",
      "Epoch: 12500/30000 Iteration: 12500 Train loss: 0.116\n",
      "Epoch: 13000/30000 Iteration: 13000 Train loss: 0.471\n",
      "Epoch: 13500/30000 Iteration: 13500 Train loss: 0.118\n",
      "Epoch: 14000/30000 Iteration: 14000 Train loss: 0.116\n",
      "Epoch: 14500/30000 Iteration: 14500 Train loss: 0.117\n",
      "Epoch: 15000/30000 Iteration: 15000 Train loss: 0.198\n",
      "Epoch: 15500/30000 Iteration: 15500 Train loss: 0.117\n",
      "Epoch: 16000/30000 Iteration: 16000 Train loss: 0.117\n",
      "Epoch: 16500/30000 Iteration: 16500 Train loss: 0.120\n",
      "Epoch: 17000/30000 Iteration: 17000 Train loss: 0.116\n",
      "Epoch: 17500/30000 Iteration: 17500 Train loss: 0.117\n",
      "Epoch: 18000/30000 Iteration: 18000 Train loss: 0.119\n",
      "Epoch: 18500/30000 Iteration: 18500 Train loss: 0.116\n",
      "Epoch: 19000/30000 Iteration: 19000 Train loss: 0.116\n",
      "Epoch: 19500/30000 Iteration: 19500 Train loss: 0.116\n",
      "Epoch: 20000/30000 Iteration: 20000 Train loss: 0.119\n",
      "Epoch: 20500/30000 Iteration: 20500 Train loss: 0.116\n",
      "Epoch: 21000/30000 Iteration: 21000 Train loss: 0.116\n",
      "Epoch: 21500/30000 Iteration: 21500 Train loss: 0.116\n",
      "Epoch: 22000/30000 Iteration: 22000 Train loss: 0.117\n",
      "Epoch: 22500/30000 Iteration: 22500 Train loss: 0.116\n",
      "Epoch: 23000/30000 Iteration: 23000 Train loss: 0.116\n",
      "Epoch: 23500/30000 Iteration: 23500 Train loss: 0.118\n",
      "Epoch: 24000/30000 Iteration: 24000 Train loss: 0.117\n",
      "Epoch: 24500/30000 Iteration: 24500 Train loss: 0.116\n",
      "Epoch: 25000/30000 Iteration: 25000 Train loss: 0.116\n",
      "Epoch: 25500/30000 Iteration: 25500 Train loss: 0.116\n",
      "Epoch: 26000/30000 Iteration: 26000 Train loss: 0.116\n",
      "Epoch: 26500/30000 Iteration: 26500 Train loss: 0.116\n",
      "Epoch: 27000/30000 Iteration: 27000 Train loss: 0.116\n",
      "Epoch: 27500/30000 Iteration: 27500 Train loss: 0.116\n",
      "Epoch: 28000/30000 Iteration: 28000 Train loss: 0.116\n",
      "Epoch: 28500/30000 Iteration: 28500 Train loss: 0.116\n",
      "Epoch: 29000/30000 Iteration: 29000 Train loss: 0.116\n",
      "Epoch: 29500/30000 Iteration: 29500 Train loss: 0.116\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d78c2bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 옵션 설정\n",
    "learning_rate = 0.0005\n",
    "n_hidden = 128\n",
    "batch_size = 16\n",
    "total_epoch = 30000\n",
    "# one hot 위한 사이즈\n",
    "n_class = n_input = dic_len\n",
    "\n",
    "# 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "# Seq2Seq 모델은 인코더의 입력과 디코더의 입력의 형식이 같다.\n",
    "enc_input = tf.placeholder(tf.int32, [None, max_input_text])\n",
    "dec_input = tf.placeholder(tf.int32, [None, max_output_text+1])\n",
    "targets = tf.placeholder(tf.int64, [None, None])\n",
    "\n",
    "\n",
    "enc_inputs_t = tf.transpose(enc_input, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_input, [1,0])\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# Attention Seq2Seq\n",
    "with tf.variable_scope(\"embedding_attention_seq2seq\"):\n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, last_state = embedding_attention_seq2seq(\n",
    "        encoder_inputs=tf.unstack(enc_inputs_t),\n",
    "        decoder_inputs=tf.unstack(dec_inputs_t),\n",
    "        cell=cell,\n",
    "        num_encoder_symbols=dic_len+1,\n",
    "        num_decoder_symbols=dic_len+2,\n",
    "        embedding_size=n_hidden,\n",
    "        feed_previous=False)\n",
    "outputs = tf.stack(dec_outputs)\n",
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=model, labels=targets))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_train():\n",
    "    plot_X = []\n",
    "    plot_Y = []\n",
    "    iteration = 0\n",
    "    for epoch in range(total_epoch):\n",
    "        input_batch, output_batch, target_batch = make_train_data(train_data, batch_size, isTrain=True)\n",
    "        _, loss = sess.run([optimizer, cost],\n",
    "                           feed_dict={enc_input: input_batch,\n",
    "                                      dec_input: output_batch,\n",
    "                                      targets: target_batch})\n",
    "        \n",
    "        if iteration%500==0:\n",
    "                print(\"Epoch: {}/{}\".format(epoch, total_epoch),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "        iteration +=1\n",
    "        \n",
    "        plot_X.append(epoch + 1)\n",
    "        plot_Y.append(loss)\n",
    "    # Graphic display\n",
    "    plt.plot(plot_X, plot_Y, label='cost')\n",
    "    plt.show()\n",
    "\n",
    "display_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 최적화가 끝난 뒤, 변수를 저장\n",
    "model_file(file_path, True)\n",
    "\n",
    "# 단어를 입력받아 번역 단어를 예측하고 디코딩하는 함수\n",
    "def predict(word):\n",
    "    word1 = []\n",
    "    for words in word:\n",
    "        word1.append(get_training_data(words))\n",
    "    input_batch, output_batch, target_batch = make_train_data([word1], batch_size, isTrain=False)\n",
    "    # 결과가 [batch size, time step, input] 으로 나오기 때문에,\n",
    "    # 2번째 차원인 input 차원을 argmax 로 취해 가장 확률이 높은 글자를 예측 값으로 만든다.\n",
    "    # http://pythonkim.tistory.com/73\n",
    "    prediction = tf.argmax(model, 2)\n",
    "    result = sess.run(prediction,\n",
    "                      feed_dict={enc_input: input_batch,\n",
    "                                 dec_input: output_batch,\n",
    "                                 targets: target_batch})\n",
    "    # 결과 값인 숫자의 인덱스에 해당하는 글자를 가져와 글자 배열을 만든다.\n",
    "    decoded = [char_array[i] for i in result[0]]\n",
    "    if 'P' in decoded:\n",
    "        end = decoded.index('P')\n",
    "        decoded = decoded[:end]\n",
    "    elif ']' in decoded:\n",
    "        end = decoded.index(']')\n",
    "        decoded = decoded[:end]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
